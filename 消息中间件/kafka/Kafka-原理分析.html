<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>生产者ACK应答机制 | winden96</title>
    <meta name="generator" content="VuePress 1.9.7">
    
    <meta name="description" content="winden96 的学习记录">
    
    <link rel="preload" href="/assets/css/0.styles.4fd6cf0c.css" as="style"><link rel="preload" href="/assets/js/app.e7c2969b.js" as="script"><link rel="preload" href="/assets/js/2.94d3dfac.js" as="script"><link rel="preload" href="/assets/js/27.44aebb00.js" as="script"><link rel="prefetch" href="/assets/js/10.27cdeca9.js"><link rel="prefetch" href="/assets/js/11.07a9d483.js"><link rel="prefetch" href="/assets/js/12.2505f188.js"><link rel="prefetch" href="/assets/js/13.0d8bcb67.js"><link rel="prefetch" href="/assets/js/14.a1698ea2.js"><link rel="prefetch" href="/assets/js/15.dce506f4.js"><link rel="prefetch" href="/assets/js/16.82ab8250.js"><link rel="prefetch" href="/assets/js/17.1fa3722a.js"><link rel="prefetch" href="/assets/js/18.129b810d.js"><link rel="prefetch" href="/assets/js/19.7531d5a3.js"><link rel="prefetch" href="/assets/js/20.2c5f040e.js"><link rel="prefetch" href="/assets/js/21.635435c4.js"><link rel="prefetch" href="/assets/js/22.a44576c7.js"><link rel="prefetch" href="/assets/js/23.32ee5f65.js"><link rel="prefetch" href="/assets/js/24.109d908c.js"><link rel="prefetch" href="/assets/js/25.9ebc3e07.js"><link rel="prefetch" href="/assets/js/26.643e2283.js"><link rel="prefetch" href="/assets/js/28.269bc50f.js"><link rel="prefetch" href="/assets/js/29.5ba9d11a.js"><link rel="prefetch" href="/assets/js/3.dc23a8fe.js"><link rel="prefetch" href="/assets/js/30.be0b3d6d.js"><link rel="prefetch" href="/assets/js/31.5c853594.js"><link rel="prefetch" href="/assets/js/32.06dd5c8a.js"><link rel="prefetch" href="/assets/js/33.66017b72.js"><link rel="prefetch" href="/assets/js/4.76c25a36.js"><link rel="prefetch" href="/assets/js/5.313f4ba0.js"><link rel="prefetch" href="/assets/js/6.3db81792.js"><link rel="prefetch" href="/assets/js/7.2b7d8442.js"><link rel="prefetch" href="/assets/js/8.19d8ddaf.js"><link rel="prefetch" href="/assets/js/9.4cbab228.js">
    <link rel="stylesheet" href="/assets/css/0.styles.4fd6cf0c.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">winden96</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>JUC</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>JVM</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Java基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>My SQL</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Mybatis Plus</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Redis</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spring Boot</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Spring Cloud</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>分布式</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>操作系统</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>杂记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>消息中间件</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/消息中间件/RabbitMQ.html" class="sidebar-link">RabbitMQ</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Kafka</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/消息中间件/kafka/Kafka-介绍与使用.html" class="sidebar-link">/消息中间件/kafka/Kafka-介绍与使用.html</a></li><li><a href="/消息中间件/kafka/Kafka-原理分析.html" aria-current="page" class="active sidebar-link">生产者ACK应答机制</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#日志清理" class="sidebar-link">日志清理</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#日志压缩" class="sidebar-link">日志压缩</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#选举机制" class="sidebar-link">选举机制</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#职责" class="sidebar-link">职责</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#介绍" class="sidebar-link">介绍</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#提交的offset值" class="sidebar-link">提交的offset值</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#获取-consumer-offsets-队列" class="sidebar-link">获取 _consumeroffsets 队列</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#offset记录机制" class="sidebar-link">offset记录机制</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#offset分区选择公式" class="sidebar-link">offset分区选择公式</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#介绍-2" class="sidebar-link">介绍</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#触发rebalance情况" class="sidebar-link">触发rebalance情况</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#rebalance过程" class="sidebar-link">Rebalance过程</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#分区分配策略" class="sidebar-link">分区分配策略</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#介绍-4" class="sidebar-link">介绍</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#follower-更新-hw-时机" class="sidebar-link">follower 更新 HW 时机</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#leader-更新-hw-时机" class="sidebar-link">leader 更新 HW 时机</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#正常情况下的hw更新过程" class="sidebar-link">正常情况下的HW更新过程</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#注意" class="sidebar-link">注意</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#follower-故障" class="sidebar-link">follower 故障</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#leader-故障" class="sidebar-link">leader 故障</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#ack-1" class="sidebar-link">ACK=1</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#写入方式" class="sidebar-link">写入方式</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#消息路由机制-分区分配" class="sidebar-link">消息路由机制（分区分配）</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#写入流程" class="sidebar-link">写入流程</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#producer-事务" class="sidebar-link">Producer 事务</a></li><li class="sidebar-sub-header"><a href="/消息中间件/kafka/Kafka-原理分析.html#consumer-事务" class="sidebar-link">Consumer 事务</a></li></ul></li><li><a href="/消息中间件/kafka/kafka-实践与调优.html" class="sidebar-link">JVM参数设置</a></li></ul></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>计算机网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>设计模式</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="生产者ack应答机制"><a href="#生产者ack应答机制" class="header-anchor">#</a> 生产者ACK应答机制</h1> <p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。</p> <p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡， 选择以下的配置。</p> <p>acks 参数配置：</p> <ul><li><p>0：<strong>producer 不等待 broker 的 ack</strong>，这一操作提供了一个最低的延迟，broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据；</p> <p>一般在大数据的场景使用，例如：用户行为日志的统计。</p></li> <li><p>1：producer 等待 broker 的 ack，<strong>partition 的 leader 成功将数据写入本地后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据</strong>；</p></li> <li><p>-1（all）：producer 等待 broker 的 ack，分区的<strong>min.insync.replicas</strong>个副本全部落盘成功后才返回 ack。但是如果在 follower 同步完成后，<strong>broker 发送 ack 之前，leader 发生故障，那么会造成数据重复（因为leader在broker发送ack之前挂掉后，producer就不会接收到ack，那么producer就会重新发送数据，而此时新选举出来的leader中已经存储了该数据，所以就造成了数据的重复）</strong>。但是在极限情况下，这种模式还是会造成数据的丢失。例如：当zk中的ISR队列里只剩当前leader，一旦这个leader挂了，那么数据也就丢失了。
<strong>一般是金融级别，或跟钱打交道的场景才会使用这种配置。</strong></p> <p><strong>min.insync.replicas</strong>代表最小要同步的副本数，默认为1，应该要配置1以上，因为如果为1的话其实就与ack设置为1的时候一样了。如果不能满足这个最小值，那么生产者将引发一个异常(NotEnoughReplicas或NotEnoughReplicasAfterAppend)。</p></li></ul> <h1 id="日志分段存储"><a href="#日志分段存储" class="header-anchor">#</a> 日志分段存储</h1> <p>kafka数据存储在磁盘中，默认保存7天。</p> <p>Kafka 一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，kafka规定了一个分区内的 .log 文件 最大为 1G，做这个限制目的是为了方便把 .log 加载到内存去操作。</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%97%A5%E5%BF%97%E5%88%86%E6%AE%B5%E5%AD%98%E5%82%A8.png" alt=""></p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E5%AD%98%E5%82%A8.png" alt=""></p> <p>segment：消息分段，由.index、.log 和 .timeindex组成，而他们的<strong>文件名代表了当前文件的起始offset</strong>。根据service.properties文件中的 log.segment.bytes （该选项指定了日志文件的大小，默认是1G）配置的值进行分段，即当前分段的.log文件大小达到了log.segment.bytes设定的值，那么就会创建新的分段，也就是新的.index、.log 和 .timeindex 文件。</p> <p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位效率低下，Kafka 采取了分片和索引机制，将每个 partition 分为多个 segment。同一分区的所有分段文件都位于同一个文件夹下（即 <strong>topic名称+分区号</strong> 目录下）。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。</p> <p>一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。</p> <p>index文件里每条记录的大小是固定的，便于查询，只需把大小和偏移量相乘便知道了当前偏移量所对应的记录，下图为 index 文件和 log 文件的结构示意图。</p> <p>注意：早期的kafka没有.timeindex文件，只有 .index 和 .log 。</p> <p><code>.index</code>是当前分段（以这个例子来说就是 [0, 5367851) 分段）的offset索引文件，kafka生产者客户端往分区发送的消息达到4K(可配置)，kafka就会记录一条当前消息的offset到index文件，即当前文件不会每条消息offset都记录，<strong>它只会记录一个批次中的最后一条消息的offset值+1和它对应log文件中的物理偏移地址，也就是说记录的是offset段。</strong></p> <div class="language- extra-class"><pre class="language-text"><code># 如果要定位消息的offset会先在这个文件里快速定位到对应offset区间的起始值，再去log文件里找具体消息
00000000000000000000.index
# 消息存储文件，主要存offset和消息体
00000000000000000000.log
# .timeindex是当前分段的消息发送时间索引文件，kafka生产者客户端往分区发送的消息达到4K(可配置), kafka就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件，记录方式与.index一样，记录一个批次中的最后一条消息的offset值与时间戳，即记录分段时间与offset。
# 如果需要按照时间来定位消息的offset，会先在这个文件里查找
00000000000000000000.timeindex

00000000000005367851.index
00000000000005367851.log
00000000000005367851.timeindex

00000000000009936472.index
00000000000009936472.log
00000000000009936472.timeindex
</code></pre></div><p><strong>通过二分查找法查找index文件中的内容。</strong></p> <p>先通过offset确定消息处在分区的哪个分段里，再通过index文件定位到offset段，<strong>获取该offset段的的起始offset对应的log文件的物理偏移地址，最后根据这个物理偏移地址到当前分段的 log 文件中查找消息。</strong></p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%97%A5%E5%BF%97%E5%88%86%E6%AE%B5%E5%AD%98%E5%82%A82.png" alt=""></p> <p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元 数据指向对应数据文件中 message 的物理偏移地址。</strong></p> <h2 id="日志清理"><a href="#日志清理" class="header-anchor">#</a> 日志清理</h2> <p>kafka 日志管理器允许定制删除策略，目前的策略是<strong>删除修改时间在N天前的日志（按时间删除）</strong></p> <p>也可以使用：保留最后的 N GB 数据的策略（按大小删除）。为了避免在删除时阻塞读操作，采用了 copy-on-write 的形式实现。删除操作进行时，读取操作的二分查找时在一个静态的快照副本上进行的</p> <p>删除思想：把 topic 中的一个 partition 大文件分成多个小文件，通过多个小文件段，很容器清除或删除已经消费完的文件，减少磁盘占用</p> <div class="language- extra-class"><pre class="language-text"><code>启用删除策略
log.cleanup.policy=delete
#专门的日志删除任务来周期性检测和删除不符合保留条件的日志分段文件，默认300000ms，5分钟
log.retention.check.interval.ms=300000
#可配置以下两个策略：
#1、清理超过指定时间清理： 
log.retention.hours=16
#2、超过指定大小后，删除旧的消息;默认值为-1，表示无穷大；
log.retention.bytes=1073741824
 
注意：#log.retention.bytes和log.retention.hours任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖
</code></pre></div><h2 id="日志压缩"><a href="#日志压缩" class="header-anchor">#</a> 日志压缩</h2> <div class="language-java extra-class"><pre class="language-java"><code>#<span class="token number">1</span>、是否开启日志压缩
log<span class="token punctuation">.</span>cleaner<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">true</span>
#<span class="token number">2</span>、启用日志压缩策略
log<span class="token punctuation">.</span>cleanup<span class="token punctuation">.</span>policy<span class="token operator">=</span>compact
</code></pre></div><p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.png" alt=""></p> <p>(1)压缩后的offset可能是不连续的，比如上图中没有5和7，因为这些offset的消息被merge了，当从这些offset消费消息时，将会拿到比这个offset大的offset对应的消息，比如，当试图获取offset为5的消息时，实际上会拿到offset为6的消息，并从这个位置开始消费。</p> <p>(2)压缩策略支持删除，当某个Key的最新版本的消息没有内容时，这个Key将被删除，这也符合以上逻辑。</p> <h1 id="controller"><a href="#controller" class="header-anchor">#</a> Controller</h1> <h2 id="选举机制"><a href="#选举机制" class="header-anchor">#</a> 选举机制</h2> <p>在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，<strong>zookeeper会保证有且仅有一个broker能创建成功，这个broker 就会成为集群的总控器controller</strong>。当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就会再次尝试竞争创建临时节点。</p> <h2 id="职责"><a href="#职责" class="header-anchor">#</a> 职责</h2> <p>具备控制器身份的broker需要比其他普通的broker具备的作用如下：</p> <p>1、当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。</p> <p>2、当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。</p> <p>3、当某个topic增加分区数量时，由控制器负责分区的重新分配。</p> <p>具体细节如下：</p> <ul><li><strong>监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理 broker 增减的变化。</strong></li> <li>监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。</li> <li>从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有 topic 所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化。</li> <li>更新集群的元数据信息，同步到其他普通的broker节点中。</li></ul> <h1 id="partition的副本leader选举机制"><a href="#partition的副本leader选举机制" class="header-anchor">#</a> Partition的副本Leader选举机制</h1> <p>例如：某个分区leader所在的broker挂了，由于controller注册了监听broker节点的事件，所以会感知到有broker挂了，而后controller会从 parititon 的 replicas 列表中取出第一个broker作为leader，当然这个broker需要也同时存在于ISR列表里。</p> <h1 id="消费者自动分区公式"><a href="#消费者自动分区公式" class="header-anchor">#</a> 消费者自动分区公式</h1> <p>hash(key)%partitionNum</p> <p>key是consumer发送消息时的key</p> <h1 id="消费者的offset"><a href="#消费者的offset" class="header-anchor">#</a> 消费者的offset</h1> <h2 id="介绍"><a href="#介绍" class="header-anchor">#</a> 介绍</h2> <p>consumerGroupId+topic+分区号确定了唯一的offset，它表示当前消费者消费到了某个主题分区的某条消息。每个consumer是基于自己在commit log中的消费进度(offset)来进行工作的。在kafka中，offset 由 consumer 自己来维护。而这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer 来说，都是没有影响的，因为每个consumer维护各自的offset且一个消费者组中只能有一个消费者消费同一个分区。<strong>所以说kafka集群是无状态的，性能不会因为 consumer数量受太多影响。kafka还将很多关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便。</strong></p> <p>一般情况下按照顺序逐条消费commit log中的消息，当然可以通过指定offset来重复消费某些消息， 或者跳过某些消息。</p> <p>consumer启动时会获取一次offset，而后在自己的内存中进行维护。</p> <h2 id="提交的offset值"><a href="#提交的offset值" class="header-anchor">#</a> 提交的offset值</h2> <p>消费者提交消费位移时提交的是当前消费到的最新消息的 offset+1。</p> <h2 id="获取-consumer-offsets-队列"><a href="#获取-consumer-offsets-队列" class="header-anchor">#</a> 获取 __consumer_offsets 队列</h2> <p>Kafka 0.9 版本之前，consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始， consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets。</p> <p>1）修改配置文件</p> <p>consumer.properties exclude.internal.topics=false</p> <p>2）读取 offset</p> <p>0.11.0.0 之前版本:</p> <div class="language-sh extra-class"><pre class="language-sh"><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter <span class="token string">&quot;kafka.coordinator.GroupMetadataManager\<span class="token variable">$OffsetsMessageFormatter</span>&quot;</span> --consumer.config config/consumer.properties --from-beginning
</code></pre></div><p>0.11.0.0 之后版本(含):</p> <div class="language-sh extra-class"><pre class="language-sh"><code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter <span class="token string">&quot;kafka.coordinator.group.GroupMetadataManager\<span class="token variable">$OffsetsMessageFormatter</span>&quot;</span> --consumer.config config/consumer.properties --frombeginning
</code></pre></div><h2 id="offset记录机制"><a href="#offset记录机制" class="header-anchor">#</a> offset记录机制</h2> <p>由于 consumer 在消费过程中可能会出现断电宕机等故障，consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要记录自己消费到了哪个 offset，以便故障恢复后继续消费。</p> <p>每个consumer会定期将自己消费分区的offset提交给kafka内部topic（__consumer_offsets），提交过去的时候，key是 consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的那条数据。</p> <p>因为__consumer_offsets可能会接收到高并发的请求，kafka默认给其分配50个分区(可以通过 offsets.topic.num.partitions设置)，这样可以通过加机器的方式提高并发性能。</p> <h2 id="offset分区选择公式"><a href="#offset分区选择公式" class="header-anchor">#</a> offset分区选择公式</h2> <p>hash(consumer group id) % __consumer_offsets主题的分区数</p> <h1 id="消费者rebalance机制"><a href="#消费者rebalance机制" class="header-anchor">#</a> 消费者Rebalance机制</h1> <h2 id="介绍-2"><a href="#介绍-2" class="header-anchor">#</a> 介绍</h2> <p>消费者rebalance就是说如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区分配给他。</p> <h2 id="触发rebalance情况"><a href="#触发rebalance情况" class="header-anchor">#</a> 触发rebalance情况</h2> <ul><li>consumer所在服务重启或宕机了</li> <li>动态给topic增加了分区</li> <li>消费组订阅了更多的topic</li></ul> <h2 id="rebalance过程"><a href="#rebalance过程" class="header-anchor">#</a> Rebalance过程</h2> <p>当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段。</p> <blockquote><p>组协调器GroupCoordinator：每个consumer group都会选择一个<strong>broker</strong>作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance（含选举consumer LeaderCoordinator）。</p></blockquote> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85Rebalance%E6%9C%BA%E5%88%B6-Rebalance%E8%BF%87%E7%A8%8B.png" alt=""></p> <p><strong>第一阶段：选择组协调器</strong></p> <p>consumer group 中的每个consumer启动时会向kafka集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接。</p> <p><strong>组协调器选举方式</strong>：</p> <p>通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker 就是这个consumer group的coordinator。</p> <p>公式：hash(consumer group id) % __consumer_offsets主题的分区数</p> <p><strong>第二阶段：加入消费者组（JOIN GROUP）</strong></p> <p>在成功找到消费组所对应的 GroupCoordinator 之后就进入 加入消费组 的阶段，在此阶段的消费者会向 GroupCoordinator 发送 <strong>JoinGroupRequest</strong> 请求，并处理响应。然后 GroupCoordinator 从 consumer group 中选择第一个加入 group 的 consumer 作为 LeaderCoordinator (<strong>消费组协调器</strong>)，把consumer group情况发送给这个LeaderCoordinator，接着这个 leader会负责制定分区方案。</p> <p><strong>第三阶段（ SYNC GROUP)</strong></p> <p>consumer LeaderCoordinator 通过给GroupCoordinator发送 <strong>SyncGroupRequest</strong>，接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader broker进行网络连接以及消息消费。</p> <h2 id="分区分配策略"><a href="#分区分配策略" class="header-anchor">#</a> 分区分配策略</h2> <h3 id="介绍-3"><a href="#介绍-3" class="header-anchor">#</a> 介绍</h3> <p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及到 partition 的分配问题，即确定哪个 partition 由哪个 consumer 来消费。</p> <p>Kafka 有三种分配策略：RoundRobin、Range 和 sticky。</p> <h3 id="range"><a href="#range" class="header-anchor">#</a> Range</h3> <p><strong>默认分配策略</strong></p> <p>以主题为单位进行划分，订阅的每个主题都会执行如下的分配规则：</p> <ul><li><p>首先，将分区按分区序号排行序，消费者按名称的字典序排序。</p></li> <li><p>然后，**用分区总数除以消费者总数。如果能够除尽，则平均分配；若除不尽，则位于排序前面的消费者将多负责一个分区。**即假设 n＝分区数／消费者数量 = 3， m＝分区数%消费者数量 = 1，那么前 m 个（含m）消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区。</p> <p>公式：
n = 单个主题分区数 / 消费者数
m = 单个主题分区数 % 消费者数</p> <p>前m个（包括m）消费者消费n+1个分区，剩余消费者消费n个分区。</p></li></ul> <p>分区分配的算法如下：</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token annotation punctuation">@Override</span>
<span class="token keyword">public</span>  <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> <span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">&gt;</span></span> partitionsPerTopic<span class="token punctuation">,</span>
                                                 <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Subscription</span><span class="token punctuation">&gt;</span></span> subscriptions<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> consumersPerTopic <span class="token operator">=</span> <span class="token function">consumersPerTopic</span><span class="token punctuation">(</span>subscriptions<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> assignment <span class="token operator">=</span>  <span class="token keyword">new</span>  <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span>  <span class="token punctuation">(</span><span class="token class-name">String</span> memberId <span class="token operator">:</span> subscriptions<span class="token punctuation">.</span><span class="token function">keySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        assignment<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>memberId<span class="token punctuation">,</span>  <span class="token keyword">new</span>  <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//for循环对订阅的多个topic分别进行处理</span>
    <span class="token keyword">for</span>  <span class="token punctuation">(</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> topicEntry <span class="token operator">:</span> consumersPerTopic<span class="token punctuation">.</span><span class="token function">entrySet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">String</span> topic <span class="token operator">=</span> topicEntry<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumersForTopic <span class="token operator">=</span> topicEntry<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Integer</span> numPartitionsForTopic <span class="token operator">=</span> partitionsPerTopic<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span>  <span class="token punctuation">(</span>numPartitionsForTopic <span class="token operator">==</span>  <span class="token keyword">null</span> <span class="token punctuation">)</span>
            <span class="token keyword">continue</span> <span class="token punctuation">;</span>
        <span class="token comment">//对消费者进行排序</span>
        <span class="token class-name">Collections</span><span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span>consumersForTopic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//计算平均每个消费者分配的分区数</span>
        <span class="token keyword">int</span>  numPartitionsPerConsumer <span class="token operator">=</span> numPartitionsForTopic <span class="token operator">/</span> consumersForTopic<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//计算平均分配后多出的分区数</span>
        <span class="token keyword">int</span>  consumersWithExtraPartition <span class="token operator">=</span> numPartitionsForTopic <span class="token operator">%</span> consumersForTopic<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">&gt;</span></span> partitions <span class="token operator">=</span> <span class="token class-name">AbstractPartitionAssignor</span><span class="token punctuation">.</span><span class="token function">partitions</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> numPartitionsForTopic<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span>  <span class="token punctuation">(</span> <span class="token keyword">int</span>  i <span class="token operator">=</span>  <span class="token number">0</span> <span class="token punctuation">,</span> n <span class="token operator">=</span> consumersForTopic<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">//计算第i个消费者，分配分区的起始位置</span>
            <span class="token keyword">int</span>  start <span class="token operator">=</span> numPartitionsPerConsumer <span class="token operator">*</span> i <span class="token operator">+</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">min</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> consumersWithExtraPartition<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">//计算第i个消费者，分配到的分区数量</span>
            <span class="token keyword">int</span>  length <span class="token operator">=</span> numPartitionsPerConsumer <span class="token operator">+</span> <span class="token punctuation">(</span>i <span class="token operator">+</span>  <span class="token number">1</span>  <span class="token operator">&gt;</span> consumersWithExtraPartition <span class="token operator">?</span>  <span class="token number">0</span>  <span class="token operator">:</span>  <span class="token number">1</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>
            assignment<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>consumersForTopic<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>partitions<span class="token punctuation">.</span><span class="token function">subList</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> start <span class="token operator">+</span> length<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span>  assignment<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre></div><p>假设，有1个主题、10个分区、3个消费者线程， 10 / 3 = 3，而且除不尽，那么消费者C1将会多消费一个分区，分配结果是：</p> <ul><li>C1将消费T1主题的0、1、2、3分区。</li> <li>C2将消费T1主题的4、5、6分区。</li> <li>C3将消费T1主题的7、8、9分区</li></ul> <p>假如，同一消费者组里的消费者C1和C2，订阅了2个主题（T0和T1），它们都有3个分区。</p> <p>分配过程：</p> <p>T0的分区数 / 消费者总数 = 3 / 2 = 1，除不尽余1，那么消费者C1将会多消费一个分区；</p> <p>T1的分区数 / 消费者总数 = 3 / 2 = 1，除不尽余1，那么消费者C1将会多消费一个分区；</p> <p>所以分配结果是：</p> <ul><li>C1将消费T0主题的 0、1 号分区，以及T1主题的 0、1 号分区。（T0-0，T0-1，T1-0，T1-1）</li> <li>C2将消费T0主题的 2 号分区，以及T1主题的 2 号分区。（T0-2，T1-2）</li></ul> <p>假设，同一消费者组里的消费者C1和C2，分别订阅了2个主题，C1订阅了T0，C2订阅了T1。</p> <p>分配结果：</p> <p>C1将消费T0的所有分区，C2将消费T1的所有分区。</p> <blockquote><p>这种分配方式存在着明显的一个问题，随着消费者订阅的Topic的数量的增加，不均衡的问题会越来越严重。</p></blockquote> <h3 id="roundrobin"><a href="#roundrobin" class="header-anchor">#</a> RoundRobin</h3> <p>轮询分配分区策略。</p> <p>以消费者组为单位进行划分</p> <p>把消费者组订阅的所有partition根据hash运算结果排序，然后<strong>轮询 consumer 为它们分配partition</strong>，尽可能的把partition均匀的分配给consumer。</p> <p><strong>1、如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor策略的分区分配会是均匀的。</strong></p> <p>假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2，t1p0、t1p1、t1p2。</p> <p>假设分区排序结果为：t0p0、t0p1、t0p2，t1p0、t1p1、t1p2。</p> <p>最终的分配结果为：</p> <p>消费者C0：t0p0、t0p2、t1p1</p> <p>消费者C1：t0p1、t1p0、t1p2</p> <p><strong>2、如果同一个消费组内的消费者所订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个topic，那么在分配分区的时候此消费者将分配不到这个topic的任何分区。</strong></p> <p>假如有3个Topic，T0（三个分区P0-0，P0-1，P0-2），T1(三个分区P1-0，P1-1，P1-2)，T2(三个分区P2-0，P2-1，P2-2)。</p> <p>有三个消费者：C0(订阅了T0),   C1（订阅了T0，T1），C2(订阅了T0，T1，T2)。</p> <p>那么分区过程如下：</p> <p>1）、通过哈希运算对消费者组的所有主题分区进行排序。假设排序后情况：P0-0，P0-1，P0-2，P1-0，P1-1，P1-2，P2-0，P2-1，P2-2。</p> <p>2）、轮询消费者，分配分区。分配过程如下：</p> <ul><li>P0-0分配给C0</li> <li>P0-1分配给C1</li> <li>P0-2分配给C2</li> <li>P1-0分配给C0但是C0并没订阅T1，于是跳过C0把P1-0分配给C1，</li> <li>P1-1分配给C2，</li> <li>P1-2分配给C0但是C0并没订阅T1，于是跳过C0把P1-2分配给C1，</li> <li>依照如上步骤，T2的分区都会分配给C2。</li></ul> <p>C0：P0-0
C1：P1-0，P1-2
C2：P1-1，P2-0，P2-1，P2-2</p> <p>可以发现C2承担了4个分区的消费还不够均衡，而C1订阅了T1，如果把 P1-1 交给C1消费能更加的均衡。</p> <blockquote><p>RoundRobin方式适用于消费者组里的消费者订阅的主题一致。</p></blockquote> <h3 id="sticky"><a href="#sticky" class="header-anchor">#</a> Sticky</h3> <p>Kafka从0.11.x版本开始引入这种分配策略。</p> <p>它的目的是在执行一次新的分配时，能在上一次分配的结果的基础上，尽量少的调整分区分配的变动，节省因分区分配变化带来的开销。</p> <p>没有发生rebalance时，Sticky分配策略和RoundRobin分配策略类似。</p> <p>Sticky是“粘性的”，可以理解为分配结果是带“粘性的”——每一次分配变更相对上一次分配做最少的变动。其目标有两点：</p> <ul><li>分区的分配要尽可能的均匀；</li> <li>在发生rebalance（重新分配分区）时，分区的分配尽可能的与上次分配的保持相同。当这两个目标发生冲突时，优先保证第一个目标。第一个目标是每个分配算法都尽量尝试去完成的，而第二个目标才真正体现出StickyAssignor特性的。</li></ul> <p>举例：</p> <p><strong>消费者订阅相同 Topic</strong></p> <p>假设消费组内有3个消费者：C0、C1和C2，它们都订阅了4个主题：t0、t1、t2、t3，并且每个主题有2个分区，也就是说整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下：</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky.png" alt=""></p> <p>消费者C0：t0p0、t1p1、t3p0
消费者C1：t0p1、t2p0、t3p1
消费者C2：t1p0、t2p1</p> <p>假设此时消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下：</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky2.png" alt=""></p> <p>消费者C0：t0p0、t1p0、t2p0、t3p0
消费者C2：t0p1、t1p1、t2p1、t3p1</p> <p>如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为：</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky3.png" alt=""></p> <p>消费者C0：t0p0、t1p1、t3p0、t2p0
消费者C2：t1p0、t2p1、t0p1、t3p1</p> <p>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。</p> <p>如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。</p> <p><strong>消费者订阅不同 Topic</strong></p> <p>同样消费组内有3个消费者：C0、C1和C2，集群中有3个主题：t0、t1和t2，这3个主题分别有1、2、3个分区，也就是说集群中有t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。消费者C0订阅了主题t0，消费者C1订阅了主题t0和t1，消费者C2订阅了主题t0、t1和t2。</p> <p>如果此时采用RoundRobinAssignor策略，那么最终的分配结果如下所示：</p> <p>( 红线是订阅，其他颜色的线是分配分区 )</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky4.png" alt=""></p> <p>消费者C0：t0p0
消费者C1：t1p0
消费者C2：t1p1、t2p0、t2p1、t2p2</p> <p>如果此时采用的是StickyAssignor策略，那么最终的分配结果为：
( 红线是订阅，其他颜色的线是分配分区 )</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky5.png" alt=""></p> <p>消费者C0：t0p0
消费者C1：t1p0、t1p1
消费者C2：t2p0、t2p1、t2p2</p> <p>可以看到这是一个最优解。</p> <p>假如此时消费者C0脱离了消费组，那么RoundRobin策略的分配结果为：
( 红线是订阅，其他颜色的线是分配分区 )</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky6.png" alt=""></p> <p>消费者C1：t0p0、t1p1
消费者C2：t1p0、t2p0、t2p1、t2p2</p> <p>可以看到RoundRobinAssignor策略保留了消费者C1和C2中原有的3个分区的分配：t2p0、t2p1和t2p2</p> <p>而如果采用的是StickyAssignor策略，那么分配结果为：
( 红线是订阅，其他颜色的线是分配分区 )</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-Sticky7.png" alt=""></p> <p>消费者C1：t1p0、t1p1、t0p0
消费者C2：t2p0、t2p1、t2p2</p> <p>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：t1p0、t1p1、t2p0、t2p1、t2p2。</p> <p>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂，如果一个 group 里面，不同的 Consumer 订阅不同的 topic, 那么设置Sticky 分配策略还是很有必要的。</p> <h1 id="hw-和-leo"><a href="#hw-和-leo" class="header-anchor">#</a> HW 和 LEO</h1> <h2 id="介绍-4"><a href="#介绍-4" class="header-anchor">#</a> 介绍</h2> <p>HW（High Watermark，高水位）：取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW。consumer最多只能消费到HW所在的位置。另外每个replica都有HW,leader和follower各自负责更新自己的HW的状态。对于<strong>leader新写入的消息，consumer不能立刻消费</strong>，<strong>leader会等待该消息被所有ISR中的replicas同步后再更新HW</strong>，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。</p> <p>LEO：指的是每个副本最大的 offset；</p> <h2 id="follower-更新-hw-时机"><a href="#follower-更新-hw-时机" class="header-anchor">#</a> follower 更新 HW 时机</h2> <p><strong>follower更新HW发生在其更新LEO之后，一旦follower向log写完数据，它会尝试更新它自己的HW值</strong>。具体算法就是比较当前 LEO 值与FETCH响应中 leader 的 HW 值，取两者中的小者作为新的 HW 值。这告诉我们一个事实：即使 follower 的LEO 值超过了 leader 的HW值，follower 的 HW 值也不会越过 leader 的 HW 值。</p> <h2 id="leader-更新-hw-时机"><a href="#leader-更新-hw-时机" class="header-anchor">#</a> leader 更新 HW 时机</h2> <p>leader的HW值就是分区HW值，因此何时更新这个值是我们最关心的，因为它直接影响了分区数据对于consumer的可见性 。以下4种情况下leader会尝试去更新分区HW——切记是尝试，有可能因为不满足条件而不做任何更新：</p> <ul><li>副本成为leader副本时：当某个副本成为了分区的leader副本，Kafka会尝试去更新分区HW。这是显而易见的道理，毕竟分区leader发生了变更，这个副本的状态是一定要检查的！</li> <li>broker出现崩溃导致副本被踢出ISR时：若有broker崩溃则必须查看下是否会波及此分区，因此检查下分区HW值是否需要更新是有必要的。</li> <li>producer向leader副本写入消息时：因为写入消息会更新leader的LEO，故有必要再查看下HW值是否也需要修改</li> <li>leader处理follower FETCH请求时：当leader处理follower的FETCH请求时首先会从底层的log读取数据，之后会尝试更新分区HW值</li></ul> <p>特别注意上面4个条件中的最后两个。它揭示了一个事实——当Kafka broker都正常工作时，分区HW值的更新时机有两个：leader处理PRODUCE请求时和leader处理FETCH请求时。</p> <p>具体：https://www.cnblogs.com/huxi2b/p/7453543.html</p> <h2 id="正常情况下的hw更新过程"><a href="#正常情况下的hw更新过程" class="header-anchor">#</a> 正常情况下的HW更新过程</h2> <p>当producer生产消息至broker后，ISR以及HW和LEO的流转过程：</p> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程.png)</p> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程2.png)</p> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程3.png)</p> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程4.png)</p> <h2 id="注意"><a href="#注意" class="header-anchor">#</a> 注意</h2> <p><strong>HW只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p> <h1 id="broker故障情况分析"><a href="#broker故障情况分析" class="header-anchor">#</a> broker故障情况分析</h1> <h2 id="follower-故障"><a href="#follower-故障" class="header-anchor">#</a> follower 故障</h2> <p>某个 follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，该 follower 会读取当前自身的 HW，<strong>并将 log 文件高于这个 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 follower 的 LEO 大于等于该 leader 的  HW 时重新加入 ISR 。</strong></p> <h2 id="leader-故障"><a href="#leader-故障" class="header-anchor">#</a> leader 故障</h2> <p>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后为保证多个副本之间的数据一致性，<strong>其余的 follower 会先将各自的 log 文件中高于自身 HW 的部分截掉，然后从新的 leader 同步数据。当原本的leader副本恢复后，它会先将log 文件中高于自身 HW 的部分截取掉，从自身的 HW 开始向新 leader 进行同步。等该 follower 的 LEO 大于等于该 leader 的  HW 时重新加入 ISR 。</strong></p> <h1 id="数据丢失情况分析"><a href="#数据丢失情况分析" class="header-anchor">#</a> 数据丢失情况分析</h1> <h2 id="ack-1"><a href="#ack-1" class="header-anchor">#</a> ACK=1</h2> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程.png)</p> <p>![](https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/HW 和 LEO-正常情况下的HW更新过程2.png)</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90-ACK=1.png" alt=""></p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90-ACK=1-2.png" alt=""></p> <h1 id="生产者发布消息机制"><a href="#生产者发布消息机制" class="header-anchor">#</a> 生产者发布消息机制</h1> <h2 id="写入方式"><a href="#写入方式" class="header-anchor">#</a> 写入方式</h2> <p>producer 采用 <strong>push 模式将消息发布到 broker，每条消息都被 append 到 patition 的分段log文件中，顺序写磁盘（顺序写磁盘 效率比随机写内存要高，保障 kafka 吞吐率）。</strong></p> <h2 id="消息路由机制-分区分配"><a href="#消息路由机制-分区分配" class="header-anchor">#</a> 消息路由机制（分区分配）</h2> <p>producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：</p> <ul><li>指定了 patition，则直接使用；</li> <li>未指定 patition 但指定 key，通过将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</li> <li>patition 和 key 都未指定，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。（其实就是使用轮询算法选出一个 patition。）</li></ul> <h2 id="写入流程"><a href="#写入流程" class="header-anchor">#</a> 写入流程</h2> <p>以ACK=-1，min.insync.replicas=2的情况为例。</p> <p><img src="https://raw.githubusercontent.com/winden96/kafka-study/master/img-Kafka-%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E5%B8%83%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6-%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.png" alt=""></p> <ol><li>producer发送消息时消息会先发送到本地缓冲区，而批量发送线程会从这个缓冲区里获取消息，当满足两个条件（1、多条消息容量达到ProducerConfig.BATCH_SIZE_CONFIG设置的大小，2、距离上一次发送的延迟时间达到ProducerConfig.LINGER_MS_CONFIG设置的值）中的任意一个时，就会触发真正的发送。</li> <li>producer 先从 zookeeper 的 &quot;/brokers/topics/某主题/partitions/某分区/state&quot; 节点找到该 partition 的 leader。</li> <li>producer 将消息发送给该 leader。</li> <li>leader 将消息写入本地 log。</li> <li>followers 从 leader pull 消息，写入本地 log 后 向leader 发送 ACK。</li> <li>leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK。</li></ol> <h1 id="创建主题流程"><a href="#创建主题流程" class="header-anchor">#</a> 创建主题流程</h1> <p>1）会在 zookeeper 中的/brokers/topics 节点下创建一个新的 topic 节点，如： /brokers/topics/first。</p> <p>2）触发 Controller 的监听程序。</p> <p>3）kafka Controller 负责 topic 的创建工作，并更新 metadata cache。</p> <h1 id="事务"><a href="#事务" class="header-anchor">#</a> 事务</h1> <p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基 础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p> <h2 id="producer-事务"><a href="#producer-事务" class="header-anchor">#</a> Producer 事务</h2> <p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer 获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction ID 获得原来的 PID。</p> <p>为了管理 Transaction，Kafka 引入了一个新的组件 Transaction Coordinator。Producer 就 是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于 事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p> <p>设置<code>properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);</code>  不过这个默认就是 true，如果显示为 false，会抛出异常</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token comment">/**
 * 配置事务
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProducerTransactionSend</span> <span class="token punctuation">{</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> topic <span class="token operator">=</span> <span class="token string">&quot;heima&quot;</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> brokerList <span class="token operator">=</span> <span class="token string">&quot;182.xxx:9092&quot;</span><span class="token punctuation">;</span>
  	<span class="token comment">// 事务 id</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> transactionId <span class="token operator">=</span> <span class="token string">&quot;transactionId&quot;</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>KEY_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>VALUE_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> brokerList<span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>TRANSACTIONAL_ID_CONFIG<span class="token punctuation">,</span> transactionId<span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>ENABLE_IDEMPOTENCE_CONFIG<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 初始化事务</span>
        producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 开启事务</span>
        producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">&quot;message-1&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record1<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record2 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">&quot;message-2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record2<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record3 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">&quot;message-3&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record3<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 结束事务</span>
        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>

</code></pre></div><p>要么全部成功，要么全部失败，一条消息都没有抛出，此外还可直接通过 <code>@Transactional</code> 注解实现</p> <h2 id="consumer-事务"><a href="#consumer-事务" class="header-anchor">#</a> Consumer 事务</h2> <p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访 问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被 删除的情况。</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/消息中间件/kafka/Kafka-介绍与使用.html" class="prev">
        /消息中间件/kafka/Kafka-介绍与使用.html
      </a></span> <span class="next"><a href="/消息中间件/kafka/kafka-实践与调优.html">
        JVM参数设置
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e7c2969b.js" defer></script><script src="/assets/js/2.94d3dfac.js" defer></script><script src="/assets/js/27.44aebb00.js" defer></script>
  </body>
</html>
